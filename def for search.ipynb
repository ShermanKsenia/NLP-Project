{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c133501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pymorphy2\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "883260eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ('NOUN', 'ADJ', 'COMP', 'VERB', 'INFN', 'PRT', 'GRND', 'NUMR', 'ADVB', 'NPRO', 'PRED', 'PREP', 'CONJ', 'PRCL', 'INTJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "117a6dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(word):\n",
    "    w = morph.parse(word)\n",
    "    l = w[0].normal_form\n",
    "    return (l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3fb9c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_one_word(phrase):\n",
    "    to_search = {'token': '', 'lemma': '', 'pos': ''}\n",
    "    if phrase[0].upper() in tags:\n",
    "        phrase = phrase[0].upper()\n",
    "        to_search['pos'] = phrase\n",
    "        #print('ищем в столбце pos')\n",
    "    else:\n",
    "        phrase = phrase[0].lower()\n",
    "        if re.search(r'[a-z]', phrase):\n",
    "            print('Латинские символы могут быть использованы только для частеречных тегов')\n",
    "            return None\n",
    "        elif phrase[0] == '\"':\n",
    "            to_search['token'] = phrase[1:-1]\n",
    "            #print('ищем в столбце token')\n",
    "        else:\n",
    "            l = lemmatization(phrase)\n",
    "            to_search['lemma'] = l\n",
    "    return to_search\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "457d6fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_and_tag(phrase):\n",
    "    if re.search(r'[a-z]', phrase[0].lower()):\n",
    "        print('Формат введенного запроса неверный')\n",
    "        return None\n",
    "    else:\n",
    "        to_search = {'token': '', 'lemma': '', 'pos': ''}\n",
    "        w = phrase[0].lower() #слово\n",
    "        if w[0] == '\"':\n",
    "            to_search['token'] = w[1:-1]\n",
    "        else:\n",
    "            l = lemmatization(w)\n",
    "            to_search['lemma'] = l\n",
    "        p = phrase[1].upper()\n",
    "        if p not in tags:\n",
    "            print('Указан неправильный частеречный тег')\n",
    "            return None\n",
    "        else:\n",
    "            to_search['pos'] = p\n",
    "            return to_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7c1cb3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'token': '', 'lemma': 'очень', 'pos': ''}, {'token': '', 'lemma': '', 'pos': 'ADJ'}, {'token': 'функция', 'lemma': '', 'pos': 'NOUN'}]\n"
     ]
    }
   ],
   "source": [
    "def main_search(q):\n",
    "    if re.search(r'[^a-zA-Zа-яА-Я +\"]', q):\n",
    "        print('В запросе присутствуют некорректные символы')\n",
    "        return None\n",
    "    else:\n",
    "        request = []\n",
    "        q = q.split()\n",
    "        if len(q) > 3:\n",
    "            print('Превышена длина запроса')\n",
    "        elif len(q) == 1:    # значит в запросе одно слово\n",
    "            q1 = q[0].split('+')\n",
    "            if len(q1) == len(q):    # либо только токен, либо только тег\n",
    "                result = only_one_word(q1)\n",
    "                if result is not None:\n",
    "                    request = result\n",
    "            else:    # в запросе токен и тег\n",
    "                result = token_and_tag(q1)\n",
    "                if result is not None:\n",
    "                    request = result\n",
    "        else:    # в запросе не одно слово\n",
    "            for element in q:\n",
    "                q1 = element.split('+')\n",
    "                if len(q1) == 1:    # либо только токен, либо только тег\n",
    "                    result = only_one_word(q1)\n",
    "                    if result is not None:\n",
    "                        request.append(result)\n",
    "                    else:\n",
    "                        request = []\n",
    "                        break\n",
    "                else:    # в запросе токен и тег\n",
    "                    result = token_and_tag(q1)\n",
    "                    if result is not None:\n",
    "                        request.append(result)\n",
    "                    else:\n",
    "                        request = []\n",
    "                        break\n",
    "    return request\n",
    "\n",
    "q = 'очень ADJ \"функция\"+NOUN'    # сюда введите запрос\n",
    "print(main_search(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53141bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
